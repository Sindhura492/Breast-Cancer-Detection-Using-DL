[model-evaluation] 
[model-evaluation] Add evaluation script for confusion matrix
[model-evaluation] Integrate sklearn classification report
[model-evaluation] Add precision, recall, F1-score computation
[model-evaluation] Visualize confusion matrix with seaborn
[model-evaluation] Add accuracy/loss comparison graphs
[model-evaluation] Evaluate on test_images directory
[model-evaluation] Document evaluation workflow in README
[model-evaluation] Refactor evaluation into notebook format
[model-evaluation] Add confidence score calculation
[model-evaluation] Fix color map for confusion matrix visualization
[model-evaluation] Add per-class accuracy breakdown
[model-evaluation] Optimize evaluation speed
[model-evaluation] Add save-to-CSV for metrics
[model-evaluation] Document evaluation results with plots
[model-evaluation] Add support for multi-run comparison
